{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Master DataFrame with all the JSON Data\n",
    "\n",
    "We compiled a list of JSON files, each corresponding to an image file, by appending relevant information. The purpose of this process is to train the dataset using the JSON data. The goal is to label the training dataset by marking words in the address if they appear in the Tesseract-extracted dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = \"./Input/jsons_data\"\n",
    "json_files = glob.glob(f\"{json_file_path}/*.json\")\n",
    "\n",
    "json_collection = []\n",
    "\n",
    "# Loop through all JSON files\n",
    "for file in json_files: \n",
    "    with open(file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "        # Extract the ID from the filename and add it to the dictionary for mapping downstream\n",
    "        file_name = file.replace(\"./Input/jsons_data\\\\W2_\", '').replace(\".json\", \"\")\n",
    "        data['file'] = file_name\n",
    "\n",
    "        # Append the DataFrame to the collection\n",
    "        json_collection.append(data)\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "json_df = pd.DataFrame(json_collection)\n",
    "\n",
    "json_df.to_csv('W2_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the dataframe\n",
    "json_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_address_objects(df):\n",
    "    address_objects = {}  # Initialize an empty dictionary\n",
    "    df.apply(lambda row: address_objects.update({row['file']: row[\"Employee's address\"]}), axis=1)\n",
    "    return address_objects  # Return the list after processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1000': '31403 David Circles Suite 863, West Erinfort, WY',\n",
       " '1001': '613 Roger Crest Apt. 802, Leeton, IA',\n",
       " '1002': '2199 Little Falls, Snyderton, TX',\n",
       " '1003': '6503 John Stream, New Meredithstad, MI',\n",
       " '1004': '95060 Crystal Burg Apt. 070, Davisburgh, AR',\n",
       " '1005': '41435 Hughes Drive, New Teresaberg, KS',\n",
       " '1006': '95842 Freeman Coves Apt. 609, Robertburgh, MA',\n",
       " '1007': '341 Charles Mountains, Morganberg, CO',\n",
       " '1008': '84813 Eric Way Apt. 116, North Amberborough, AR',\n",
       " '1009': '730 Huber Island Suite 344, Collinshaven, IN',\n",
       " '1010': '9622 Jessica Estates Apt. 532, Nathantown, IA',\n",
       " '1011': '08470 Miller Stream, Petersmouth, IN',\n",
       " '1012': '68390 Blackwell Drive, South Robert, MD',\n",
       " '1013': '27374 Henderson Oval, Lake James, NJ',\n",
       " '1014': '917 April Isle, New Taylor, IL',\n",
       " '1015': '672 Brian Common Suite 123, East Lisa, UT',\n",
       " '1016': '73200 Tammy Bridge Apt. 560, Chadfort, ND',\n",
       " '1017': '83396 Cross Pines Suite 762, Johnstonville, SC',\n",
       " '1018': '8632 Mcclure Curve, Gailfort, NJ',\n",
       " '1019': '5688 Poole Falls, Stevenborough, IL',\n",
       " '1020': '1982 Fitzgerald Motorway Suite 99',\n",
       " '1021': '165 Brown Street Apt. 864, South Robertmouth, TN',\n",
       " '1022': '384 John Passage Suite 913, Lake Jasmine, WI',\n",
       " '1023': '06811 Mark Street, Lake Ronniestad, VA',\n",
       " '1024': '0699 Cory Manors Suite 511, Douglaschester, OR',\n",
       " '1025': '549 Wagner Turnpike, NOrth Jamesburgh, KS',\n",
       " '1026': '87089 Henderson Island Suite 647, Roachborough, NJ',\n",
       " '1027': '768 Watts Stravenue Suite 613',\n",
       " '1028': '26195 Shelly Station, Christopherville, NM',\n",
       " '1029': '477 Cory Keys, West Michaelburgh, AL',\n",
       " '1030': '220 Foley Ford Suite 426, Landryside, VT',\n",
       " '1031': '96453 Molly Hollow Apt. 124, East Kathrynmouth, AL',\n",
       " '1032': '667 Moreno Islands Apt. 604, West John, NE',\n",
       " '1033': '04274 Trevor Prairie Apt. 381, WHitefort, MA',\n",
       " '1034': '66050 Hunt Valleys Apt. 689, Michaelport, WY',\n",
       " '1035': '869 Rodger Mountains, Ryanfurt, OK',\n",
       " '1036': '80934 Nicole Extensions, Johnsshire, WA',\n",
       " '1037': '267 Austin Unions Suite 494, Lake Joshuaside, NJ',\n",
       " '1038': '267 Austin Unions Suite 494, Lake Joshuaside, NJ',\n",
       " '1039': '32247 Lisa Curve Suite 086, Michaelport, HI',\n",
       " '1040': '438 Brandon Point Apt. 407, Lake Victoriamouth, WA',\n",
       " '1041': '965 Rodgers Lake Apt. 548, New Denise, NC',\n",
       " '1042': '3916 Stevens Center Apt. 868, South Laura, SD',\n",
       " '1043': '77681 Jose Roads, South William, MN',\n",
       " '1044': '41137 Adams Parkways Suite 509, Carterchester, AR',\n",
       " '1045': '42449 Chelsea Wells, East Douglas, LA'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_address_objects(json_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses = create_address_objects(json_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path = './Input/W2\\W2_XL_input_clean_1000.JPG'\n",
    "train_folder_path = './Input/W2/Train'\n",
    "train_files = glob.glob(f\"{train_folder_path}/*.JPG\")\n",
    "train_ocr_collection = []\n",
    "\n",
    "for image_path in train_files:\n",
    "\n",
    "    ocr_data = pytesseract.image_to_data(image_path, output_type=pytesseract.Output.DICT)\n",
    "    ocr_df = pd.DataFrame(ocr_data)\n",
    "\n",
    "    file_name = image_path.replace(\"./Input/W2/Train\\\\W2_XL_input_clean_\", '').replace(\".jpg\", \"\")\n",
    "    address_bow = addresses[file_name].replace(',', '').split(' ')\n",
    "\n",
    "    # Add width and height\n",
    "    ocr_df['bottom'] = ocr_df['top'] + ocr_df['height']\n",
    "    ocr_df['right'] = ocr_df['left'] + ocr_df['width']\n",
    "\n",
    "    # Create a target column\n",
    "    ocr_df.loc[(ocr_df['text'].isin(address_bow))  & (ocr_df['top'].astype('int') > 300) & (ocr_df['top'].astype('int') < 800), 'label'] = 1\n",
    "\n",
    "    # ocr_df[\"label\"].fillna(0, inplace=True)\n",
    "    ocr_df[\"label\"] = ocr_df[\"label\"].fillna(0)\n",
    "\n",
    "    # Add the dataframe to the collection\n",
    "    train_ocr_collection.append(ocr_df)\n",
    "\n",
    "# Combine all OCR DataFrames into a single DataFrame\n",
    "train_df = pd.concat(train_ocr_collection, ignore_index=True)\n",
    "\n",
    "# Save as CSV (optional)\n",
    "train_df.to_csv(\"W2_training_data.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>page_num</th>\n",
       "      <th>block_num</th>\n",
       "      <th>par_num</th>\n",
       "      <th>line_num</th>\n",
       "      <th>word_num</th>\n",
       "      <th>left</th>\n",
       "      <th>top</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>conf</th>\n",
       "      <th>text</th>\n",
       "      <th>bottom</th>\n",
       "      <th>right</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>396</td>\n",
       "      <td>44</td>\n",
       "      <td>17</td>\n",
       "      <td>96</td>\n",
       "      <td>730</td>\n",
       "      <td>413</td>\n",
       "      <td>110</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>396</td>\n",
       "      <td>78</td>\n",
       "      <td>17</td>\n",
       "      <td>96</td>\n",
       "      <td>Huber</td>\n",
       "      <td>413</td>\n",
       "      <td>207</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>226</td>\n",
       "      <td>396</td>\n",
       "      <td>94</td>\n",
       "      <td>17</td>\n",
       "      <td>96</td>\n",
       "      <td>Island</td>\n",
       "      <td>413</td>\n",
       "      <td>320</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>338</td>\n",
       "      <td>396</td>\n",
       "      <td>77</td>\n",
       "      <td>17</td>\n",
       "      <td>96</td>\n",
       "      <td>Suite</td>\n",
       "      <td>413</td>\n",
       "      <td>415</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>434</td>\n",
       "      <td>396</td>\n",
       "      <td>44</td>\n",
       "      <td>17</td>\n",
       "      <td>96</td>\n",
       "      <td>344</td>\n",
       "      <td>413</td>\n",
       "      <td>478</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>435</td>\n",
       "      <td>190</td>\n",
       "      <td>17</td>\n",
       "      <td>89</td>\n",
       "      <td>Collinshaven</td>\n",
       "      <td>452</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>338</td>\n",
       "      <td>436</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "      <td>91</td>\n",
       "      <td>IN</td>\n",
       "      <td>452</td>\n",
       "      <td>368</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     level  page_num  block_num  par_num  line_num  word_num  left  top  \\\n",
       "288      5         1         35        1        16         1    66  396   \n",
       "289      5         1         35        1        16         2   129  396   \n",
       "290      5         1         35        1        16         3   226  396   \n",
       "291      5         1         35        1        16         4   338  396   \n",
       "292      5         1         35        1        16         5   434  396   \n",
       "297      5         1         35        1        17         1    65  435   \n",
       "298      5         1         35        1        17         2   338  436   \n",
       "\n",
       "     width  height  conf          text  bottom  right  label  \n",
       "288     44      17    96           730     413    110    1.0  \n",
       "289     78      17    96         Huber     413    207    1.0  \n",
       "290     94      17    96        Island     413    320    1.0  \n",
       "291     77      17    96         Suite     413    415    1.0  \n",
       "292     44      17    96           344     413    478    1.0  \n",
       "297    190      17    89  Collinshaven     452    255    1.0  \n",
       "298     30      16    91            IN     452    368    1.0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr_df.loc[ocr_df['label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = ' '.join(ocr_df.loc[ocr_df['label'] == 1]['text'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the Test folder\n",
    "\n",
    "test_folder_path = './Input/W2/Test'\n",
    "test_files = glob.glob(f\"{test_folder_path}/*.JPG\")\n",
    "\n",
    "test_ocr_collection = []  # Store test DataFrames\n",
    "\n",
    "for file in test_files:  # List of PDFs in the test folder\n",
    "    \n",
    "    ocr_data = pytesseract.image_to_data(image_path, output_type=pytesseract.Output.DICT)\n",
    "    ocr_df = pd.DataFrame(ocr_data)\n",
    "\n",
    "    file_name = image_path.replace(\"./Input/W2/Train\\\\W2_XL_input_clean_\", '').replace(\".jpg\", \"\")\n",
    "    address_bow = addresses[file_name].replace(',', '').split(' ')\n",
    "\n",
    "    # Add width and height\n",
    "    ocr_df['bottom'] = ocr_df['top'] + ocr_df['height']\n",
    "    ocr_df['right'] = ocr_df['left'] + ocr_df['width']\n",
    "\n",
    "    # NO LABELS for test data\n",
    "    test_ocr_collection.append(ocr_df)\n",
    "\n",
    "# Merge into a single test DataFrame\n",
    "test_df = pd.concat(test_ocr_collection, ignore_index=True)\n",
    "test_df.to_csv(\"W2_test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numerical features for training\n",
    "feature_columns = [\"left\", \"top\", \"width\", \"height\", \"bottom\", \"right\"]\n",
    "\n",
    "X_train = train_df[feature_columns]\n",
    "X_test = test_df[feature_columns]\n",
    "y_train = train_df[\"label\"]  # Target variable (1 for document number, 0 for others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=2)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "test_df[\"predicted_label\"]  = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "869 Roger Mountains Ryanfurt OK\n"
     ]
    }
   ],
   "source": [
    "image_path = \"./Input/W2/Test/W2_XL_input_clean_1035.jpg\"\n",
    "\n",
    "\n",
    "# Perform OCR\n",
    "ocr_data = pytesseract.image_to_data(image_path, output_type=pytesseract.Output.DICT)\n",
    "final_df = pd.DataFrame(ocr_data)\n",
    "\n",
    "\n",
    "# Compute Bounding Box Details\n",
    "final_df['bottom'] = final_df['top'] + final_df['height']\n",
    "final_df['right'] = final_df['left'] + final_df['width']\n",
    "\n",
    "# Select relevant features for model prediction\n",
    "X_test = final_df[feature_columns]\n",
    "\n",
    "new_clf = KNeighborsClassifier(n_neighbors=2)\n",
    "new_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict Document Numbers\n",
    "final_df[\"predicted_label\"] = new_clf.predict(X_test)\n",
    "\n",
    "# Return only text identified as a document number\n",
    "address = ' '.join(final_df.loc[final_df['predicted_label'] == 1]['text'].to_list())\n",
    "\n",
    "print(address)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
