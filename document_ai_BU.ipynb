{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_images = convert_from_path(\"Input/set-1/SP_MIS02824100914340 1.pdf\")\n",
    "image = pdf_images[0].convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manually set the full path to tesseract.exe\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "ocr_data = pytesseract.image_to_data(image, output_type=pytesseract.Output.DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Words:  ['VEHICLE', 'LOADING', 'REPORT', '-', 'BILL', 'OF', 'LADING', 'Page:', '2', '530', 'RAPPORT', 'DE', 'CHARGEMENT', '-', 'VEHICULE', '-', 'CONNAISSEMENT', 'DOGUMENTNUMBER', '6363', '|', '—', 'RATE', 'SYEPER', 'oy', '|', 'Ne', 'bUDOCUMENT', 'mia/ad/', 'yy', '24', 'HOUR', 'NUMBER', '(613]996-6666', '-', 'NUMERO', '24', 'HEURES', '0362418', '10/006', '10/07/24', '‘COLLECT', '-', 'FRAIS', 'VIRES', '|', 'CONSIGNEE;CUSTOMER', '-', 'DESTINATAIRE/CLIENT', 'Roo', 'eyaaeeNent', '|', 'CONSIGNOR', '-', 'EXPEDITEUR', '|', 'nora', '|', 'PETRO', 'CANADA', 'LUBRICANTS', 'INC', '0005064508', '|SUNCOR', 'ENERGY', 'MONTREAL', '0082041', 'PCLI', '-', 'QUEBEC', '302', '0009406423', '11675', 'rue', 'Sherbrooke', 'est', 'oO', '385', 'SOUTHDOWN', 'ROAD', 'Montreal,', 'QC', 'H1B', '103', '(613)', '996-6666', 'MISSISSAUGA,', 'ON', 'LSJ', '2Y¥3', '__', 'ee', 'Yannick', 'Mercier', 'RELEASE', '(C-of-A)', 'NUMBER', 'CUSTOMER', 'PURCHASE', 'ORDER', 'NUMBER', 'No', 'OE', 'DEMANCE', 'DU', 'CLIENT', 'TCARRIER-TRANSPORTEUR', 'OO', '_', 'GEO', 'A', 'HALL', '9401535', 'Vesicte', 'NUMBER', 'LICENSE', 'NUMBER', 'ADDRESS', 'OF', 'METER', 'AND', 'TRADER', '-', '_', '8800', '-', '6E', 'CROISSANT', 'No', 'DU', 'VEHICULE', 'NOMBRE', 'OE', 'PERMIS', '|', \"L'ADRESSE\", 'DE', 'METRE', 'ET', 'DE', 'COMMERCANT', 'ANJOU', '7', 'ee', '1136', '11675', 'rue', 'Sherbrooke', 'est', 'HlJ', '1Al1', '|', 'GERI', 'eb', 'FéanseOmTE', 'se', '1921', 'Montreal,', 'OC', 'H1B', '1C3', '|', '(514)', '352-5550', '(613)', '996-6666', '——————', '—=', 'L', '=', '.', '———', '|', 'MEASURED', '|', 'PRODUCTMETER', 'PRODUCT', 'DESCRIPTION', '-', 'DESCRIPTION', 'DU', 'PRODUIT', 'UTRES', 'CORRECTED', '|', 'TEMP', '|', 'DENSITY', 'PRODUIT/METER', 'oe', '-', '-', 'MESUREES', 'TO18G', '|CELSIUS|', 'DENSITE', '|', '|', '103265', '|', 'NOT', 'REGULATED', 'UNDER', 'TDG', '0.9642', '43998', '42423', '|61.7', '|910.6', 'MTR271', '|)', 'HEAVY', 'VACUUM', 'GASOIL(HVGO)', 'API', '54B', 'of', 'A,', '|', 'Dont', '.', 'Total', 'Litres', 'by', 'Product', '|', '103265', 'HEAVY', 'VACUUM', 'GASOTL', '(HVGO)', '43998', '42423', '|', 'hereby', 'declare', 'that', 'the', 'contents', 'of', 'this', 'consignment', 'are', 'fully', 'and', 'accurately', 'described', 'above', 'by', 'Ine', 'proper', 'shipping', 'fame,', 'are', 'properly', 'classified', 'and', 'packaged,', 'have', 'dangerous', 'goods', 'safely', 'marks', 'properly', 'affixed', 'or', 'displayed', 'on', 'them.', 'and', 'are', 'in', 'all', 'respects', 'in', 'proper', 'condition', 'for', 'transport', 'according', 'lo', 'Ihe', 'Transportation', 'of', 'Dangerous', 'Goods', 'Regulations', '|', '—', 'TIME', 'IN', 'T', '~', 'START', 'LOADING', 'FINISHLOADING.', '|', 'TIMEOUT', '|', 'Yannick', 'Mercier', 'ARRIVEE', 'DESUT', 'DU', 'CHARGEMENT', '|', 'FIN', 'DU', 'CHARGEMENT', 'DEPART', 'Shipper', 'name', '(please', 'print)', '00:31', '|', '00:36', '00:59', '00:59', '|', '\"', 'ORIVER', 'NAME', '-', 'NOM', 'DU', 'CONDUCTEUA', 'NOBIVER', 'NUMBER', '|', 'DRIVES#SIGNATURE', '-', 'SIGNATURE', 'DU', 'CONDUCTEUR', 'TOTAL', 'QUANTITY', '-', 'QUANT.', 'TOTALE', '-', '43998', 'Litres', 'SYLVAIN', 'GAREAU', '00007148', 'PRODUCT', '|', 'TANK', 'CAPACITY', 'WATER', 'DIP/BEFORE', 'DIPS|', 'SEFORE', 'INVENT', '|', 'AFTER', 'DIPS|', 'ENM{AG', 'INVENT', 'PRODUCT', '|', 'TANK', 'CAPACITY|', 'WATER', 'DIF|', 'BEFORE', 'DIPS', '|', 'BEFORE', 'INVENT', '|', 'AFTER', 'DIPS|', 'ENDING', 'INVENT', 'PRODUIT', '|', 'CONTENANCE', '|', 'MEASURE', '|', 'AVANT', 'LE', 'INVENTAIRE', 'APRES', 'LE', 'VENTAIRE', 'PRODUIT', '|', 'CONTENANCE', '|', 'MEASURE', '|', 'AVANT', 'LE.', 'INVENTAIRE', '|', 'APRESLE', '|', 'INVENTAIRE', 'P', 'RESERVIOR', '|', 'DEAU', '|', 'JAUGEAGE', 'JAUGEAGE', 'YAUGEAGE', '|4/', 'AF', '____|DURESERVIOR', '|', 'DEAU', 'JAUGEAGE', 'JAUGEAGE', '|', 'JAUGEAGE']\n",
      "Bounding Boxes:  [[896, 90, 1012, 112], [1023, 91, 1144, 113], [1156, 92, 1269, 113], [1278, 104, 1285, 106], [1296, 92, 1350, 113], [1360, 92, 1396, 113], [1407, 92, 1506, 114], [132, 122, 205, 144], [230, 120, 242, 144], [461, 122, 508, 148], [799, 118, 930, 146], [941, 120, 975, 140], [986, 120, 1182, 147], [1192, 132, 1198, 134], [1208, 120, 1345, 142], [1356, 132, 1362, 135], [1373, 120, 1612, 142], [121, 150, 317, 165], [347, 151, 407, 169], [463, 150, 464, 162], [494, 140, 507, 179], [523, 148, 566, 171], [572, 144, 631, 172], [640, 161, 656, 172], [48, 193, 50, 198], [120, 168, 143, 184], [151, 168, 293, 184], [506, 166, 606, 215], [612, 166, 643, 215], [784, 185, 813, 206], [824, 184, 901, 207], [920, 185, 1027, 206], [1043, 183, 1257, 204], [1295, 198, 1301, 200], [1313, 186, 1433, 208], [1443, 187, 1472, 208], [1483, 186, 1594, 209], [133, 211, 242, 230], [264, 212, 357, 231], [512, 212, 640, 233], [1030, 210, 1176, 238], [1164, 206, 1181, 243], [1192, 217, 1264, 239], [1278, 217, 1357, 239], [47, 230, 49, 242], [62, 226, 246, 265], [260, 244, 267, 256], [274, 236, 457, 266], [672, 241, 702, 267], [700, 241, 848, 267], [832, 237, 844, 271], [847, 242, 958, 260], [951, 237, 960, 271], [965, 243, 1070, 260], [1433, 244, 1437, 246], [1448, 244, 1597, 269], [47, 270, 48, 292], [131, 274, 210, 291], [228, 274, 327, 291], [344, 274, 508, 292], [529, 275, 574, 292], [662, 273, 838, 293], [845, 276, 942, 294], [961, 276, 1059, 294], [1077, 276, 1208, 294], [1463, 276, 1574, 295], [131, 304, 192, 321], [213, 312, 224, 314], [245, 304, 341, 325], [362, 304, 406, 322], [662, 302, 823, 323], [845, 306, 923, 323], [944, 310, 992, 324], [1012, 306, 1175, 324], [1194, 308, 1240, 324], [1546, 304, 1610, 305], [131, 333, 175, 351], [197, 334, 342, 352], [361, 335, 425, 352], [842, 336, 985, 357], [1011, 338, 1041, 358], [1061, 337, 1109, 354], [1129, 337, 1172, 355], [1267, 337, 1335, 357], [1349, 338, 1473, 355], [129, 364, 319, 384], [344, 365, 376, 382], [394, 364, 442, 382], [461, 364, 505, 382], [285, 412, 306, 414], [384, 413, 435, 414], [835, 394, 959, 418], [976, 395, 1092, 414], [261, 416, 323, 427], [328, 416, 376, 429], [381, 416, 440, 427], [552, 417, 629, 428], [635, 417, 711, 428], [716, 418, 765, 428], [770, 418, 829, 429], [602, 431, 618, 441], [623, 431, 640, 442], [646, 431, 715, 442], [720, 432, 738, 442], [744, 431, 792, 442], [46, 478, 288, 504], [480, 480, 546, 483], [715, 482, 747, 483], [129, 515, 177, 532], [194, 515, 210, 532], [227, 516, 291, 532], [561, 515, 672, 534], [718, 531, 788, 544], [794, 524, 864, 545], [907, 532, 977, 545], [983, 532, 1054, 546], [1116, 526, 1194, 546], [1200, 533, 1222, 546], [1228, 533, 1285, 546], [1291, 533, 1325, 546], [1331, 533, 1398, 546], [1473, 526, 1481, 527], [1574, 526, 1603, 528], [131, 544, 192, 562], [212, 553, 224, 556], [246, 544, 275, 562], [294, 546, 441, 564], [721, 554, 741, 566], [747, 554, 769, 566], [775, 554, 857, 567], [907, 554, 979, 568], [985, 554, 1006, 568], [1013, 554, 1075, 568], [1081, 546, 1090, 578], [1103, 555, 1192, 568], [1198, 555, 1220, 568], [1226, 555, 1282, 568], [1290, 555, 1310, 568], [1316, 555, 1336, 568], [1343, 555, 1463, 568], [128, 570, 209, 602], [460, 598, 463, 599], [579, 598, 662, 599], [711, 576, 772, 595], [1095, 578, 1172, 596], [1193, 583, 1241, 596], [1260, 578, 1424, 597], [1444, 581, 1490, 598], [129, 605, 177, 624], [197, 605, 240, 624], [460, 622, 461, 644], [476, 604, 507, 630], [520, 605, 532, 630], [544, 600, 632, 648], [640, 606, 653, 630], [710, 608, 773, 626], [1092, 609, 1234, 630], [1260, 610, 1290, 631], [1309, 609, 1358, 628], [1378, 610, 1422, 628], [1612, 621, 1613, 632], [135, 634, 202, 655], [213, 634, 339, 653], [1099, 638, 1167, 659], [1180, 638, 1306, 657], [48, 659, 170, 683], [299, 675, 355, 676], [447, 664, 469, 677], [821, 677, 832, 678], [1265, 679, 1267, 681], [1392, 679, 1610, 681], [1112, 686, 1113, 692], [1145, 687, 1238, 701], [1265, 686, 1266, 696], [59, 694, 201, 708], [352, 709, 432, 723], [438, 710, 550, 723], [556, 718, 560, 719], [567, 710, 679, 724], [685, 711, 707, 724], [714, 711, 787, 725], [1159, 707, 1216, 721], [1290, 699, 1394, 713], [1401, 695, 1412, 737], [1423, 699, 1468, 713], [1482, 695, 1493, 737], [1510, 700, 1580, 713], [59, 722, 194, 744], [301, 745, 427, 747], [757, 747, 763, 748], [1037, 748, 1047, 749], [1141, 727, 1237, 750], [1314, 727, 1376, 750], [1412, 727, 1481, 741], [1510, 728, 1590, 751], [1599, 750, 1612, 752], [45, 761, 46, 771], [129, 757, 222, 775], [237, 753, 252, 786], [258, 759, 307, 776], [326, 759, 473, 777], [492, 760, 573, 777], [591, 760, 640, 777], [960, 761, 1055, 779], [1160, 761, 1238, 779], [1310, 762, 1388, 780], [1411, 762, 1471, 781], [1487, 757, 1571, 781], [127, 788, 223, 806], [236, 784, 250, 815], [259, 790, 340, 807], [358, 790, 458, 807], [475, 789, 666, 810], [957, 793, 1005, 809], [1027, 791, 1074, 809], [298, 985, 359, 1180], [424, 989, 532, 1176], [44, 1176, 45, 1186], [523, 1151, 605, 1206], [485, 1191, 522, 1212], [290, 1489, 370, 1507], [390, 1488, 486, 1508], [506, 1489, 538, 1512], [557, 1490, 670, 1508], [1262, 1463, 1264, 1504], [258, 1519, 352, 1538], [456, 1521, 538, 1538], [555, 1521, 656, 1539], [672, 1522, 768, 1540], [779, 1521, 864, 1542], [1157, 1523, 1236, 1542], [1308, 1523, 1385, 1542], [56, 1697, 58, 1710], [65, 1697, 114, 1714], [121, 1697, 173, 1710], [179, 1698, 205, 1711], [211, 1697, 232, 1711], [238, 1699, 299, 1712], [305, 1698, 318, 1712], [324, 1698, 348, 1712], [354, 1699, 447, 1716], [453, 1703, 476, 1712], [482, 1699, 510, 1716], [516, 1699, 542, 1712], [548, 1700, 623, 1716], [629, 1700, 699, 1714], [706, 1701, 750, 1714], [756, 1700, 773, 1717], [778, 1701, 800, 1714], [806, 1704, 853, 1717], [858, 1701, 919, 1718], [56, 1719, 100, 1733], [107, 1720, 129, 1730], [135, 1717, 194, 1734], [199, 1717, 265, 1731], [272, 1718, 297, 1731], [304, 1718, 378, 1735], [385, 1719, 420, 1732], [425, 1719, 502, 1736], [508, 1719, 552, 1736], [559, 1719, 602, 1736], [608, 1719, 651, 1733], [658, 1719, 717, 1737], [722, 1720, 770, 1734], [776, 1723, 790, 1734], [796, 1720, 865, 1737], [871, 1723, 887, 1734], [894, 1721, 933, 1735], [56, 1737, 82, 1750], [88, 1740, 111, 1750], [117, 1740, 127, 1750], [134, 1737, 149, 1750], [155, 1738, 224, 1754], [222, 1741, 232, 1750], [239, 1741, 286, 1754], [292, 1738, 356, 1751], [363, 1738, 381, 1751], [386, 1740, 451, 1755], [457, 1739, 527, 1755], [534, 1740, 546, 1752], [552, 1739, 574, 1752], [579, 1740, 685, 1756], [692, 1740, 705, 1753], [712, 1740, 791, 1756], [796, 1740, 844, 1754], [851, 1740, 970, 1757], [945, 1733, 953, 1761], [957, 1733, 974, 1761], [974, 1748, 1007, 1760], [1013, 1749, 1025, 1760], [1066, 1745, 1069, 1747], [1105, 1738, 1114, 1765], [1109, 1745, 1161, 1760], [1166, 1745, 1227, 1761], [1309, 1746, 1584, 1762], [1458, 1741, 1492, 1767], [1502, 1746, 1572, 1762], [1595, 1746, 1609, 1748], [125, 1762, 239, 1782], [255, 1764, 370, 1783], [974, 1763, 1035, 1774], [1087, 1763, 1132, 1774], [1137, 1764, 1155, 1774], [1160, 1763, 1259, 1775], [1269, 1754, 1280, 1785], [1298, 1764, 1318, 1775], [1324, 1764, 1342, 1775], [1348, 1764, 1446, 1775], [1509, 1764, 1564, 1776], [139, 1796, 194, 1828], [201, 1796, 234, 1828], [241, 1800, 295, 1821], [303, 1796, 340, 1828], [957, 1798, 1036, 1816], [1067, 1816, 1068, 1819], [1125, 1799, 1201, 1817], [1324, 1799, 1402, 1818], [1491, 1800, 1568, 1818], [1609, 1805, 1610, 1810], [42, 1824, 45, 1826], [47, 1824, 116, 1842], [123, 1829, 169, 1842], [175, 1836, 179, 1839], [190, 1830, 220, 1843], [230, 1825, 249, 1843], [249, 1825, 372, 1844], [561, 1823, 637, 1863], [647, 1832, 709, 1859], [734, 1827, 736, 1831], [758, 1828, 913, 1853], [919, 1840, 923, 1842], [930, 1828, 1054, 1846], [1036, 1823, 1056, 1857], [1061, 1827, 1177, 1847], [1262, 1829, 1316, 1847], [1322, 1830, 1415, 1848], [1410, 1825, 1418, 1857], [1421, 1830, 1484, 1848], [1489, 1834, 1552, 1848], [823, 1859, 827, 1861], [1307, 1860, 1386, 1879], [1422, 1860, 1518, 1879], [126, 1888, 239, 1905], [290, 1888, 388, 1906], [591, 1888, 719, 1907], [65, 1917, 131, 1928], [143, 1911, 157, 1943], [158, 1918, 194, 1928], [199, 1918, 266, 1929], [272, 1918, 321, 1929], [327, 1918, 412, 1930], [417, 1919, 448, 1930], [467, 1919, 522, 1930], [528, 1920, 578, 1930], [589, 1911, 597, 1943], [602, 1920, 646, 1931], [652, 1920, 683, 1931], [695, 1920, 747, 1939], [752, 1920, 803, 1931], [848, 1920, 915, 1931], [928, 1914, 938, 1942], [938, 1921, 975, 1932], [980, 1921, 1048, 1932], [1056, 1922, 1105, 1932], [1111, 1922, 1131, 1932], [1142, 1922, 1197, 1932], [1202, 1922, 1234, 1932], [1243, 1914, 1253, 1942], [1258, 1922, 1314, 1933], [1320, 1922, 1370, 1933], [1373, 1914, 1381, 1942], [1386, 1922, 1430, 1933], [1436, 1922, 1466, 1933], [1481, 1922, 1533, 1933], [1538, 1923, 1588, 1934], [67, 1934, 128, 1945], [147, 1927, 157, 1955], [161, 1934, 255, 1945], [269, 1934, 270, 1944], [276, 1935, 342, 1946], [350, 1927, 357, 1955], [367, 1935, 412, 1946], [417, 1936, 432, 1946], [481, 1928, 562, 1956], [608, 1936, 654, 1947], [659, 1936, 675, 1947], [722, 1937, 790, 1948], [850, 1937, 911, 1948], [927, 1930, 937, 1958], [942, 1937, 1038, 1949], [1044, 1930, 1054, 1958], [1059, 1938, 1126, 1949], [1133, 1930, 1140, 1958], [1152, 1938, 1198, 1949], [1203, 1938, 1218, 1949], [1272, 1938, 1354, 1949], [1373, 1931, 1383, 1959], [1392, 1938, 1458, 1950], [1466, 1931, 1481, 1959], [1495, 1939, 1576, 1950], [151, 1950, 176, 1995], [182, 1951, 260, 1962], [271, 1944, 276, 1972], [288, 1952, 324, 1963], [341, 1944, 356, 1972], [364, 1952, 438, 1963], [485, 1952, 560, 1964], [602, 1953, 677, 1964], [692, 1968, 695, 1969], [725, 1968, 736, 1969], [885, 1954, 1043, 1971], [1050, 1946, 1058, 1975], [1071, 1954, 1107, 1965], [1150, 1954, 1224, 1966], [1277, 1955, 1352, 1966], [1368, 1947, 1381, 1975], [1386, 1955, 1460, 1966]]\n"
     ]
    }
   ],
   "source": [
    "# Extract words and their bounding boxes\n",
    "\n",
    "words = []\n",
    "boxes = []\n",
    "\n",
    "for i in range(len(ocr_data['text'])):\n",
    "    if ocr_data['text'][i].strip():\n",
    "        words.append(ocr_data['text'][i])\n",
    "        x, y, w, h = (ocr_data['left'][i], ocr_data['top'][i], ocr_data['width'][i], ocr_data['height'][i])\n",
    "        boxes.append([x, y, x+w, y+h])\n",
    "\n",
    "\n",
    "print('Extracted Words: ', words)\n",
    "print('Bounding Boxes: ', boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(words, columns=[\"words\"])\n",
    "df.to_excel(\"words.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR mistakes: VEHICLE LOADING REPORT - BILL OF LADING Page: 2 530 RAPPORT DE CHARGEMENT - VEHICULE - CONNAISSEMENT DOGUMENTNUMBER 6363 | — RATE SYEPER oy | Ne bUDOCUMENT mia/ad/ yy 24 HOUR NUMBER (613]996-6666 - NUMERO 24 HEURES 0362418 10/006 10/07/24 ‘COLLECT - FRAIS VIRES | CONSIGNEE;CUSTOMER - DESTINATAIRE/CLIENT Roo eyaaeeNent | CONSIGNOR - EXPEDITEUR | nora | PETRO CANADA LUBRICANTS INC 0005064508 |SUNCOR ENERGY MONTREAL 0082041 PCLI - QUEBEC 302 0009406423 11675 rue Sherbrooke est oO 385 SOUTHDOWN ROAD Montreal, QC H1B 103 (613) 996-6666 MISSISSAUGA, ON LSJ 2Y¥3 __ ee Yannick Mercier RELEASE (C-of-A) NUMBER CUSTOMER PURCHASE ORDER NUMBER No OE DEMANCE DU CLIENT TCARRIER-TRANSPORTEUR OO _ GEO A HALL 9401535 Vesicte NUMBER LICENSE NUMBER ADDRESS OF METER AND TRADER - _ 8800 - 6E CROISSANT No DU VEHICULE NOMBRE OE PERMIS | L'ADRESSE DE METRE ET DE COMMERCANT ANJOU 7 ee 1136 11675 rue Sherbrooke est HlJ 1Al1 | GERI eb FéanseOmTE se 1921 Montreal, OC H1B 1C3 | (514) 352-5550 (613) 996-6666 —————— —= L = . ——— | MEASURED | PRODUCTMETER PRODUCT DESCRIPTION - DESCRIPTION DU PRODUIT UTRES CORRECTED | TEMP | DENSITY PRODUIT/METER oe - - MESUREES TO18G |CELSIUS| DENSITE | | 103265 | NOT REGULATED UNDER TDG 0.9642 43998 42423 |61.7 |910.6 MTR271 |) HEAVY VACUUM GASOIL(HVGO) API 54B of A, | Dont . Total Litres by Product | 103265 HEAVY VACUUM GASOTL (HVGO) 43998 42423 | hereby declare that the contents of this consignment are fully and accurately described above by Ine proper shipping fame, are properly classified and packaged, have dangerous goods safely marks properly affixed or displayed on them. and are in all respects in proper condition for transport according lo Ihe Transportation of Dangerous Goods Regulations | — TIME IN T ~ START LOADING FINISHLOADING. | TIMEOUT | Yannick Mercier ARRIVEE DESUT DU CHARGEMENT | FIN DU CHARGEMENT DEPART Shipper name (please print) 00:31 | 00:36 00:59 00:59 | \" ORIVER NAME - NOM DU CONDUCTEUA NOBIVER NUMBER | DRIVES#SIGNATURE - SIGNATURE DU CONDUCTEUR TOTAL QUANTITY - QUANT. TOTALE - 43998 Litres SYLVAIN GAREAU 00007148 PRODUCT | TANK CAPACITY WATER DIP/BEFORE DIPS| SEFORE INVENT | AFTER DIPS| ENM{AG INVENT PRODUCT | TANK CAPACITY| WATER DIF| BEFORE DIPS | BEFORE INVENT | AFTER DIPS| ENDING INVENT PRODUIT | CONTENANCE | MEASURE | AVANT LE INVENTAIRE APRES LE VENTAIRE PRODUIT | CONTENANCE | MEASURE | AVANT LE. INVENTAIRE | APRESLE | INVENTAIRE P RESERVIOR | DEAU | JAUGEAGE JAUGEAGE YAUGEAGE |4/ AF ____|DURESERVIOR | DEAU JAUGEAGE JAUGEAGE | JAUGEAGE → Fix spelling.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"OCR mistakes: \" + \" \".join(words) + \" → Fix spelling.\"\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Bounding Boxes: [[896, 90, 1012, 112], [1023, 91, 1144, 113], [1156, 92, 1269, 113], [1278, 104, 1285, 106], [1296, 92, 1350, 113]]\n",
      "Normalized Bounding Boxes: [[527, 40, 595, 50], [601, 41, 672, 51], [680, 41, 746, 51], [751, 47, 755, 48], [762, 41, 794, 51]]\n"
     ]
    }
   ],
   "source": [
    "# Get image dimensions (width, height)\n",
    "image_width, image_height = image.size  # Assuming `image` is a PIL Image\n",
    "\n",
    "# Normalize bounding boxes to fit in [0, 1000] range\n",
    "normalized_boxes = [\n",
    "    [\n",
    "        int((x / image_width) * 1000),   # Normalize x1\n",
    "        int((y / image_height) * 1000),  # Normalize y1\n",
    "        int((x_w / image_width) * 1000), # Normalize x2\n",
    "        int((y_h / image_height) * 1000) # Normalize y2\n",
    "    ]\n",
    "    for (x, y, x_w, y_h) in boxes\n",
    "]\n",
    "\n",
    "# Debugging: Print some normalized values\n",
    "print(\"Original Bounding Boxes:\", boxes[:5])\n",
    "print(\"Normalized Bounding Boxes:\", normalized_boxes[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'QUESTION', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'QUESTION', 'QUESTION', 'QUESTION', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'ANSWER', 'O', 'ANSWER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'QUESTION', 'QUESTION', 'QUESTION', 'QUESTION', 'O', 'QUESTION', 'QUESTION', 'QUESTION', 'QUESTION', 'QUESTION', 'O', 'ANSWER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "labels_df = pd.read_excel('words.xlsx')\n",
    "labels = labels_df['labels'].to_list()\n",
    "print(\"Labels: \", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Create ner_tags\n",
    "ner_tags = []\n",
    "for i, label in enumerate(labels): \n",
    "    if label == 'QUESTION':\n",
    "        ner_tags.append(1)\n",
    "    elif label == 'ANSWER':\n",
    "        ner_tags.append(2)\n",
    "    else:\n",
    "        ner_tags.append(0)\n",
    "\n",
    "print(ner_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"id\": [\"doc1\"],\n",
    "    \"words\": [words],\n",
    "    \"bboxes\": [boxes],\n",
    "    \"ner_tags\": [ner_tags]  # 1 = QUESTION, 2 = ANSWER\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LayoutLMv3Processor, LayoutLMv3ForTokenClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'words', 'bboxes', 'ner_tags'],\n",
      "    num_rows: 1\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_dict(data)\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LayoutLMv3ForTokenClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 20.00 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'words', 'bboxes', 'ner_tags'],\n",
      "    num_rows: 1\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained LayoutLMv3 processor and model\n",
    "processor = LayoutLMv3Processor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=False)\n",
    "model = LayoutLMv3ForTokenClassification.from_pretrained(\"microsoft/layoutlmv3-base\", num_labels=3)\n",
    "\n",
    "\n",
    "def preprocess_data(examples):\n",
    "    encoding = processor(\n",
    "        images=image,\n",
    "        text=examples[\"words\"],\n",
    "        boxes=examples[\"bboxes\"],\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"max_length\",\n",
    "        truncation=True\n",
    "    )\n",
    "    encoding[\"labels\"] = examples[\"ner_tags\"]  # Add labels\n",
    "    \n",
    "\n",
    "# Apply preprocessing\n",
    "processed_dataset = dataset.map(preprocess_data)\n",
    "print(processed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./layoutlmv3-finetuned\",\n",
    "    evaluation_strategy=\"no\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=5,\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vuvee\\AppData\\Local\\Temp\\ipykernel_14724\\3140587020.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer\n\u001b[0;32m      4\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m      5\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m      6\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m      7\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mprocessed_dataset,\n\u001b[0;32m      8\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mprocessor\u001b[38;5;241m.\u001b[39mtokenizer\n\u001b[0;32m      9\u001b[0m )\n\u001b[1;32m---> 11\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[1;32mc:\\Users\\vuvee\\anaconda3\\envs\\dev\\Lib\\site-packages\\transformers\\trainer.py:2241\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2239\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   2242\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   2243\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[0;32m   2244\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[0;32m   2245\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[0;32m   2246\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\vuvee\\anaconda3\\envs\\dev\\Lib\\site-packages\\transformers\\trainer.py:2548\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2541\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2542\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2543\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2544\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[0;32m   2545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2546\u001b[0m )\n\u001b[0;32m   2547\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2548\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[0;32m   2550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2551\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2552\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2553\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2554\u001b[0m ):\n\u001b[0;32m   2555\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2556\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\vuvee\\anaconda3\\envs\\dev\\Lib\\site-packages\\transformers\\trainer.py:3698\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[0;32m   3695\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   3697\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 3698\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(model, inputs, num_items_in_batch\u001b[38;5;241m=\u001b[39mnum_items_in_batch)\n\u001b[0;32m   3700\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[0;32m   3701\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   3702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3703\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   3704\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\vuvee\\anaconda3\\envs\\dev\\Lib\\site-packages\\transformers\\trainer.py:3759\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[0;32m   3757\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[0;32m   3758\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[1;32m-> 3759\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m   3760\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   3761\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\vuvee\\anaconda3\\envs\\dev\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\vuvee\\anaconda3\\envs\\dev\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\vuvee\\anaconda3\\envs\\dev\\Lib\\site-packages\\transformers\\models\\layoutlmv3\\modeling_layoutlmv3.py:1099\u001b[0m, in \u001b[0;36mLayoutLMv3ForTokenClassification.forward\u001b[1;34m(self, input_ids, bbox, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, pixel_values)\u001b[0m\n\u001b[0;32m   1069\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;124;03m    Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;124;03m>>> logits = outputs.logits\u001b[39;00m\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;124;03m```\"\"\"\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1099\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayoutlmv3(\n\u001b[0;32m   1100\u001b[0m     input_ids,\n\u001b[0;32m   1101\u001b[0m     bbox\u001b[38;5;241m=\u001b[39mbbox,\n\u001b[0;32m   1102\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1103\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[0;32m   1104\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   1105\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m   1106\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m   1107\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1108\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1109\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1110\u001b[0m     pixel_values\u001b[38;5;241m=\u001b[39mpixel_values,\n\u001b[0;32m   1111\u001b[0m )\n\u001b[0;32m   1112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1113\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39msize()\n",
      "File \u001b[1;32mc:\\Users\\vuvee\\anaconda3\\envs\\dev\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\vuvee\\anaconda3\\envs\\dev\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\vuvee\\anaconda3\\envs\\dev\\Lib\\site-packages\\transformers\\models\\layoutlmv3\\modeling_layoutlmv3.py:887\u001b[0m, in \u001b[0;36mLayoutLMv3Model.forward\u001b[1;34m(self, input_ids, bbox, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, pixel_values, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    886\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m--> 887\u001b[0m     batch_size, seq_length \u001b[38;5;241m=\u001b[39m input_shape\n\u001b[0;32m    888\u001b[0m     device \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=processed_dataset,\n",
    "    tokenizer=processor.tokenizer\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LayoutLMv3Processor, LayoutLMv3ForTokenClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LayoutLMv3ForTokenClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\vuvee\\anaconda3\\envs\\dev\\Lib\\site-packages\\transformers\\modeling_utils.py:1072: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 16, 269, 474, 506]])\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained LayoutLMv3 processor and model\n",
    "processor = LayoutLMv3Processor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=False)\n",
    "model = LayoutLMv3ForTokenClassification.from_pretrained(\"microsoft/layoutlmv3-base\", num_labels=4)\n",
    "\n",
    "# Tokenization\n",
    "encoding = processor(images=image, text=words, boxes=normalized_boxes, return_tensors=\"pt\", padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Run model inference\n",
    "with torch.no_grad():\n",
    "    outputs = model(**encoding)\n",
    "\n",
    "# Get predicted labels\n",
    "predicted_labels = torch.argmax(outputs.logits, dim=1)\n",
    "print(predicted_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
